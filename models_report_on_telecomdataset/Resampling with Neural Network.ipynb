{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import Counter object\n",
    "from collections import Counter\n",
    "# Import pandas for reading data\n",
    "import pandas as pd\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Handling data imbalancing\n",
    "from imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n",
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import Keras \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with segmented data\n",
    "#\"\"\"select count(1) from \"AI_LAGORTA\".\"CAMP_AUG15_Y_CBM1\"\"\"\"\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import cx_Oracle\n",
    "\n",
    "\n",
    "host='192.168.113.80'\n",
    "port=1521\n",
    "sid='bbidb'\n",
    "user='system'\n",
    "password='oraclebbi'\n",
    "sid = cx_Oracle.makedsn(host, port, sid=sid)\n",
    "\n",
    "def oracle_connect(host=host, sid=sid, user=user, password=password):\n",
    "    cstr = 'oracle://{user}:{password}@{sid}/'.format (\n",
    "        user = user ,\n",
    "        password = password ,\n",
    "        sid = sid\n",
    "    )\n",
    "\n",
    "    engine = create_engine (\n",
    "        cstr ,\n",
    "        convert_unicode = False ,\n",
    "        pool_recycle = 10 ,\n",
    "        pool_size = 50 ,\n",
    "        echo =False\n",
    "    )\n",
    "\n",
    "    return engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['pk_msisdn_id', 'n_accept_optin', 'n_accept_optin_voice_local',\n",
       "        'n_count_top_ups_last_1m', 'n_data_nat_mb_avg3', 'n_months_acc',\n",
       "        'n_months_acc_optin_data', 'n_months_pr_optin',\n",
       "        'n_months_pr_optin_intl', 'n_months_pr_rew_intl',\n",
       "        'n_months_pr_rew_onnet', 'n_prop_optin_voice_local',\n",
       "        'n_reward_voice_local', 'n_value_top_ups_last_1m',\n",
       "        'n_voice_intl_rev_avg3', 'n_voice_intl_secs_avg3',\n",
       "        'n_voice_off_net_rev_avg3', 'n_voice_on_net_rev_avg3', 'total_voice',\n",
       "        'v_active_sum', 'v_customer_value$', 'nationality_group', 'target_all'],\n",
       "       dtype='object'), 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve database table\n",
    "con = oracle_connect()\n",
    "df = pd.read_sql_query('SELECT * FROM AI_LAGORTA.CAMP_AUG15_Y_CBM2', con = con)\n",
    "df.columns, len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling ordinal data\n",
    "v_customer_value_enc = OrdinalEncoder ( categories = [ [ 'LVC' , 'HVC' ] ] )\n",
    "nationality_group_enc = OrdinalEncoder ( categories = [ [ 'Low' , 'Med' , \"High\" ] ] )\n",
    "df [ 'v_customer_value$' ] = v_customer_value_enc.fit_transform (df [ 'v_customer_value$' ].values.reshape ( -1 , 1 ) )\n",
    "df [ 'nationality_group' ] = nationality_group_enc.fit_transform (df [ 'nationality_group' ].values.reshape ( -1 , 1 ) )\n",
    "# separate predictors and target\n",
    "X = df.drop(['pk_msisdn_id', 'target_all'], axis=1)\n",
    "y = df['target_all'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify = y) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16672, 7146)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' 96.42514395393475]\n",
      " ['1' 3.574856046065259]]\n"
     ]
    }
   ],
   "source": [
    "# Training class count\n",
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "percent = (counts / len(y_train)) * 100\n",
    "print(np.asarray((unique, percent)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' 6891]\n",
      " ['1' 255]]\n"
     ]
    }
   ],
   "source": [
    "# Testing class count\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "percent = counts \n",
    "print(np.asarray((unique, percent)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'0': 16076, '1': 596})\n",
      "Resampled dataset shape Counter({'0': 16076, '1': 16076})\n"
     ]
    }
   ],
   "source": [
    "# Handling data imbalancing\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch 1/50\n",
      "32152/32152 [==============================] - 28s 876us/sample - loss: 7.8131 - acc: 0.5144\n",
      "Epoch 2/50\n",
      "32152/32152 [==============================] - 29s 901us/sample - loss: 8.0569 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "32152/32152 [==============================] - 28s 882us/sample - loss: 7.4079 - acc: 0.5402\n",
      "Epoch 4/50\n",
      "32152/32152 [==============================] - 29s 902us/sample - loss: 7.2309 - acc: 0.5512\n",
      "Epoch 5/50\n",
      "32152/32152 [==============================] - 30s 918us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "32152/32152 [==============================] - 28s 879us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "32152/32152 [==============================] - 29s 899us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "32152/32152 [==============================] - 29s 902us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "32152/32152 [==============================] - 30s 918us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "32152/32152 [==============================] - 29s 897us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "32152/32152 [==============================] - 28s 866us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "32152/32152 [==============================] - ETA: 0s - loss: 8.0555 - acc: 0.500 - 28s 873us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "32152/32152 [==============================] - 28s 871us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "32152/32152 [==============================] - 30s 948us/sample - loss: 8.0590 - acc: 0.5000 - loss: 8.0631 - acc: 0.49\n",
      "Epoch 15/50\n",
      "32152/32152 [==============================] - 30s 945us/sample - loss: 8.0590 - acc: 0.5000 - loss: \n",
      "Epoch 16/50\n",
      "32152/32152 [==============================] - 31s 975us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "32152/32152 [==============================] - 31s 951us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "32152/32152 [==============================] - 31s 953us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "32152/32152 [==============================] - 31s 962us/sample - loss: 8.0590 - acc: 0.5000 - loss: 8.0 - ETA: \n",
      "Epoch 20/50\n",
      "32152/32152 [==============================] - 31s 977us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "32152/32152 [==============================] - 28s 881us/sample - loss: 8.0590 - acc: 0.5000 - loss: 8.0927 - ETA: \n",
      "Epoch 22/50\n",
      "32152/32152 [==============================] - 28s 875us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "32152/32152 [==============================] - 28s 873us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "32152/32152 [==============================] - 28s 884us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "32152/32152 [==============================] - 28s 876us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "32152/32152 [==============================] - 30s 945us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "32152/32152 [==============================] - 32s 986us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "32152/32152 [==============================] - 28s 869us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "32152/32152 [==============================] - 27s 853us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "32152/32152 [==============================] - 28s 863us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "32152/32152 [==============================] - 29s 906us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "32152/32152 [==============================] - 26s 818us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "32152/32152 [==============================] - 27s 835us/sample - loss: 8.0590 - acc: 0.5000 - loss: 8\n",
      "Epoch 34/50\n",
      "32152/32152 [==============================] - 28s 880us/sample - loss: 8.0590 - acc: 0.5000 - loss: 8.0570 - acc: 0.500\n",
      "Epoch 35/50\n",
      "32152/32152 [==============================] - 27s 853us/sample - loss: 8.0590 - acc: 0.5000 - loss: 8.0703 - \n",
      "Epoch 36/50\n",
      "32152/32152 [==============================] - 29s 914us/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "32152/32152 [==============================] - 32s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "32152/32152 [==============================] - 32s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.50001s\n",
      "Epoch 47/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "32152/32152 [==============================] - 33s 1ms/sample - loss: 8.0590 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x128b44856a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_nodes = (X_res.shape [ 1 ] ,)\n",
    "\n",
    "## Model building\n",
    "\n",
    "# model setup\n",
    "nn = Sequential ( )\n",
    "\n",
    "# Add input layer\n",
    "nn.add ( Dense ( 32 , activation = 'relu' , input_shape = input_nodes ) )\n",
    "\n",
    "# Add two hidden layers of dimension 100\n",
    "nn.add ( Dense ( 1000 , activation = 'relu' ) )\n",
    "nn.add ( Dense ( 1000 , activation = 'relu' ) )\n",
    "# nn.add ( Dense ( 800 , activation = 'relu' ) )\n",
    "# nn.add ( Dense ( 800 , activation = 'relu' ) )\n",
    "\n",
    "\n",
    "# Adding the output layer\n",
    "nn.add ( Dense ( 2 , activation = 'softmax' ) )\n",
    "\n",
    "# Model compilation\n",
    "nn.compile ( optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ] )\n",
    "\n",
    "# Model fitting\n",
    "nn.fit ( X_res, y_res, epochs = 50 )\n",
    "# y_pred_nn = nn.predict_classes ( X_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.50      1.00      0.67     16076\n",
      "     class 1       0.00      0.00      0.00     16076\n",
      "\n",
      "    accuracy                           0.50     32152\n",
      "   macro avg       0.25      0.50      0.33     32152\n",
      "weighted avg       0.25      0.50      0.33     32152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Training Data Metrics\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(metrics.classification_report(y_res.astype('int64'), nn.predict_classes(X_res), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.96      1.00      0.98      6891\n",
      "     class 1       0.00      0.00      0.00       255\n",
      "\n",
      "    accuracy                           0.96      7146\n",
      "   macro avg       0.48      0.50      0.49      7146\n",
      "weighted avg       0.93      0.96      0.95      7146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bassam.abdelmohsen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Metrics\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(metrics.classification_report(y_test.astype('int64'), nn.predict_classes(X_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
