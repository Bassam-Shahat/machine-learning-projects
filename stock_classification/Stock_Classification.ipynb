{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem defination\n",
    ">> this data set contains 3000 record and 100 feature and we want to build a classifier to predict stock either 1 or -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#importing all algorithms in sklearn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#linear classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis #quadratic instead of line\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn import neighbors #knn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read our data\n",
    "dataset=pd.read_csv('E:\\\\assignments_DRkhaled\\\\stock_classification\\\\Stock_Classification\\\\stock_data_100X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>X100</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91.567862</td>\n",
       "      <td>96.621901</td>\n",
       "      <td>98.084599</td>\n",
       "      <td>96.543909</td>\n",
       "      <td>91.678881</td>\n",
       "      <td>96.337918</td>\n",
       "      <td>96.1250</td>\n",
       "      <td>94.015957</td>\n",
       "      <td>94.409201</td>\n",
       "      <td>97.084183</td>\n",
       "      <td>...</td>\n",
       "      <td>96.888889</td>\n",
       "      <td>95.499022</td>\n",
       "      <td>97.457971</td>\n",
       "      <td>99.282297</td>\n",
       "      <td>101.296698</td>\n",
       "      <td>98.310678</td>\n",
       "      <td>100.489134</td>\n",
       "      <td>99.602234</td>\n",
       "      <td>93.263158</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.908600</td>\n",
       "      <td>97.640753</td>\n",
       "      <td>103.112398</td>\n",
       "      <td>98.130312</td>\n",
       "      <td>78.041958</td>\n",
       "      <td>97.693843</td>\n",
       "      <td>95.6250</td>\n",
       "      <td>95.744681</td>\n",
       "      <td>94.089712</td>\n",
       "      <td>96.655229</td>\n",
       "      <td>...</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>96.379804</td>\n",
       "      <td>93.397222</td>\n",
       "      <td>100.478469</td>\n",
       "      <td>101.179953</td>\n",
       "      <td>98.141624</td>\n",
       "      <td>96.084839</td>\n",
       "      <td>99.204467</td>\n",
       "      <td>86.421053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.869178</td>\n",
       "      <td>94.369892</td>\n",
       "      <td>109.018217</td>\n",
       "      <td>102.209632</td>\n",
       "      <td>73.357203</td>\n",
       "      <td>100.676878</td>\n",
       "      <td>96.9166</td>\n",
       "      <td>93.085106</td>\n",
       "      <td>98.243067</td>\n",
       "      <td>98.113343</td>\n",
       "      <td>...</td>\n",
       "      <td>101.925926</td>\n",
       "      <td>95.988415</td>\n",
       "      <td>94.412410</td>\n",
       "      <td>100.956938</td>\n",
       "      <td>99.287025</td>\n",
       "      <td>102.027024</td>\n",
       "      <td>100.326263</td>\n",
       "      <td>103.985313</td>\n",
       "      <td>77.513179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.888889</td>\n",
       "      <td>95.603221</td>\n",
       "      <td>108.459686</td>\n",
       "      <td>103.116147</td>\n",
       "      <td>77.832727</td>\n",
       "      <td>104.677398</td>\n",
       "      <td>100.8750</td>\n",
       "      <td>93.617021</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.828542</td>\n",
       "      <td>...</td>\n",
       "      <td>102.074074</td>\n",
       "      <td>102.152642</td>\n",
       "      <td>105.579469</td>\n",
       "      <td>106.937799</td>\n",
       "      <td>101.651101</td>\n",
       "      <td>103.884995</td>\n",
       "      <td>106.688139</td>\n",
       "      <td>108.525205</td>\n",
       "      <td>85.736842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1          X2          X3          X4          X5          X6  \\\n",
       "0  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "1   91.567862   96.621901   98.084599   96.543909   91.678881   96.337918   \n",
       "2   92.908600   97.640753  103.112398   98.130312   78.041958   97.693843   \n",
       "3   84.869178   94.369892  109.018217  102.209632   73.357203  100.676878   \n",
       "4   88.888889   95.603221  108.459686  103.116147   77.832727  104.677398   \n",
       "\n",
       "         X7          X8          X9         X10  ...         X92         X93  \\\n",
       "0  100.0000  100.000000  100.000000  100.000000  ...  100.000000  100.000000   \n",
       "1   96.1250   94.015957   94.409201   97.084183  ...   96.888889   95.499022   \n",
       "2   95.6250   95.744681   94.089712   96.655229  ...   97.333333   96.379804   \n",
       "3   96.9166   93.085106   98.243067   98.113343  ...  101.925926   95.988415   \n",
       "4  100.8750   93.617021  100.000000   99.828542  ...  102.074074  102.152642   \n",
       "\n",
       "          X94         X95         X96         X97         X98         X99  \\\n",
       "0  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "1   97.457971   99.282297  101.296698   98.310678  100.489134   99.602234   \n",
       "2   93.397222  100.478469  101.179953   98.141624   96.084839   99.204467   \n",
       "3   94.412410  100.956938   99.287025  102.027024  100.326263  103.985313   \n",
       "4  105.579469  106.937799  101.651101  103.884995  106.688139  108.525205   \n",
       "\n",
       "         X100  Y  \n",
       "0  100.000000  1  \n",
       "1   93.263158 -1  \n",
       "2   86.421053  1  \n",
       "3   77.513179  1  \n",
       "4   85.736842  1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 101)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>X100</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>321.301401</td>\n",
       "      <td>48.072520</td>\n",
       "      <td>148.431781</td>\n",
       "      <td>172.070840</td>\n",
       "      <td>66.914123</td>\n",
       "      <td>126.384306</td>\n",
       "      <td>63.028845</td>\n",
       "      <td>66.880979</td>\n",
       "      <td>141.522760</td>\n",
       "      <td>81.751216</td>\n",
       "      <td>...</td>\n",
       "      <td>135.922489</td>\n",
       "      <td>128.983254</td>\n",
       "      <td>162.883245</td>\n",
       "      <td>158.742236</td>\n",
       "      <td>210.373057</td>\n",
       "      <td>63.462594</td>\n",
       "      <td>127.655820</td>\n",
       "      <td>122.680072</td>\n",
       "      <td>20.092448</td>\n",
       "      <td>-0.005333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>341.287159</td>\n",
       "      <td>8.893981</td>\n",
       "      <td>45.329553</td>\n",
       "      <td>42.316404</td>\n",
       "      <td>50.233377</td>\n",
       "      <td>15.177757</td>\n",
       "      <td>22.049723</td>\n",
       "      <td>17.105684</td>\n",
       "      <td>24.788428</td>\n",
       "      <td>15.711278</td>\n",
       "      <td>...</td>\n",
       "      <td>24.967422</td>\n",
       "      <td>27.132133</td>\n",
       "      <td>74.080297</td>\n",
       "      <td>43.827855</td>\n",
       "      <td>48.051738</td>\n",
       "      <td>24.260192</td>\n",
       "      <td>59.307288</td>\n",
       "      <td>40.385987</td>\n",
       "      <td>13.453940</td>\n",
       "      <td>1.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.440392</td>\n",
       "      <td>25.994616</td>\n",
       "      <td>77.305568</td>\n",
       "      <td>77.620397</td>\n",
       "      <td>6.679720</td>\n",
       "      <td>72.677572</td>\n",
       "      <td>13.320000</td>\n",
       "      <td>41.148936</td>\n",
       "      <td>41.507987</td>\n",
       "      <td>31.801051</td>\n",
       "      <td>...</td>\n",
       "      <td>43.875556</td>\n",
       "      <td>76.947162</td>\n",
       "      <td>37.602534</td>\n",
       "      <td>67.942584</td>\n",
       "      <td>82.384089</td>\n",
       "      <td>26.594559</td>\n",
       "      <td>23.751977</td>\n",
       "      <td>33.733650</td>\n",
       "      <td>3.414737</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.483441</td>\n",
       "      <td>43.562644</td>\n",
       "      <td>104.919259</td>\n",
       "      <td>137.053824</td>\n",
       "      <td>36.735664</td>\n",
       "      <td>116.490216</td>\n",
       "      <td>47.525000</td>\n",
       "      <td>53.398936</td>\n",
       "      <td>122.722045</td>\n",
       "      <td>73.147563</td>\n",
       "      <td>...</td>\n",
       "      <td>121.096296</td>\n",
       "      <td>102.716243</td>\n",
       "      <td>114.188256</td>\n",
       "      <td>121.655502</td>\n",
       "      <td>175.495122</td>\n",
       "      <td>48.638448</td>\n",
       "      <td>79.262436</td>\n",
       "      <td>90.819819</td>\n",
       "      <td>11.680000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>186.638901</td>\n",
       "      <td>46.704518</td>\n",
       "      <td>150.946336</td>\n",
       "      <td>166.288952</td>\n",
       "      <td>49.236364</td>\n",
       "      <td>129.431162</td>\n",
       "      <td>66.420000</td>\n",
       "      <td>59.446809</td>\n",
       "      <td>143.616613</td>\n",
       "      <td>81.828530</td>\n",
       "      <td>...</td>\n",
       "      <td>134.352593</td>\n",
       "      <td>133.127202</td>\n",
       "      <td>152.927800</td>\n",
       "      <td>151.923445</td>\n",
       "      <td>205.724650</td>\n",
       "      <td>59.513433</td>\n",
       "      <td>117.924651</td>\n",
       "      <td>123.613555</td>\n",
       "      <td>16.687368</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>500.293286</td>\n",
       "      <td>50.685211</td>\n",
       "      <td>184.542462</td>\n",
       "      <td>206.005666</td>\n",
       "      <td>87.261538</td>\n",
       "      <td>138.114505</td>\n",
       "      <td>74.230000</td>\n",
       "      <td>81.662234</td>\n",
       "      <td>158.313099</td>\n",
       "      <td>92.938314</td>\n",
       "      <td>...</td>\n",
       "      <td>156.597037</td>\n",
       "      <td>149.048924</td>\n",
       "      <td>201.758304</td>\n",
       "      <td>191.837321</td>\n",
       "      <td>248.544863</td>\n",
       "      <td>67.489774</td>\n",
       "      <td>171.758116</td>\n",
       "      <td>147.674597</td>\n",
       "      <td>25.711579</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1297.606183</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>242.745101</td>\n",
       "      <td>282.436261</td>\n",
       "      <td>234.394406</td>\n",
       "      <td>156.679828</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>124.468085</td>\n",
       "      <td>203.450479</td>\n",
       "      <td>135.163112</td>\n",
       "      <td>...</td>\n",
       "      <td>192.497778</td>\n",
       "      <td>187.866928</td>\n",
       "      <td>544.546414</td>\n",
       "      <td>256.880383</td>\n",
       "      <td>319.538025</td>\n",
       "      <td>174.661791</td>\n",
       "      <td>281.421778</td>\n",
       "      <td>215.558785</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean    321.301401    48.072520   148.431781   172.070840    66.914123   \n",
       "std     341.287159     8.893981    45.329553    42.316404    50.233377   \n",
       "min      23.440392    25.994616    77.305568    77.620397     6.679720   \n",
       "25%      41.483441    43.562644   104.919259   137.053824    36.735664   \n",
       "50%     186.638901    46.704518   150.946336   166.288952    49.236364   \n",
       "75%     500.293286    50.685211   184.542462   206.005666    87.261538   \n",
       "max    1297.606183   100.000000   242.745101   282.436261   234.394406   \n",
       "\n",
       "                X6           X7           X8           X9          X10  ...  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000  ...   \n",
       "mean    126.384306    63.028845    66.880979   141.522760    81.751216  ...   \n",
       "std      15.177757    22.049723    17.105684    24.788428    15.711278  ...   \n",
       "min      72.677572    13.320000    41.148936    41.507987    31.801051  ...   \n",
       "25%     116.490216    47.525000    53.398936   122.722045    73.147563  ...   \n",
       "50%     129.431162    66.420000    59.446809   143.616613    81.828530  ...   \n",
       "75%     138.114505    74.230000    81.662234   158.313099    92.938314  ...   \n",
       "max     156.679828   120.000000   124.468085   203.450479   135.163112  ...   \n",
       "\n",
       "               X92          X93          X94          X95          X96  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean    135.922489   128.983254   162.883245   158.742236   210.373057   \n",
       "std      24.967422    27.132133    74.080297    43.827855    48.051738   \n",
       "min      43.875556    76.947162    37.602534    67.942584    82.384089   \n",
       "25%     121.096296   102.716243   114.188256   121.655502   175.495122   \n",
       "50%     134.352593   133.127202   152.927800   151.923445   205.724650   \n",
       "75%     156.597037   149.048924   201.758304   191.837321   248.544863   \n",
       "max     192.497778   187.866928   544.546414   256.880383   319.538025   \n",
       "\n",
       "               X97          X98          X99         X100            Y  \n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000  \n",
       "mean     63.462594   127.655820   122.680072    20.092448    -0.005333  \n",
       "std      24.260192    59.307288    40.385987    13.453940     1.000152  \n",
       "min      26.594559    23.751977    33.733650     3.414737    -1.000000  \n",
       "25%      48.638448    79.262436    90.819819    11.680000    -1.000000  \n",
       "50%      59.513433   117.924651   123.613555    16.687368    -1.000000  \n",
       "75%      67.489774   171.758116   147.674597    25.711579     1.000000  \n",
       "max     174.661791   281.421778   215.558785   100.000000     1.000000  \n",
       "\n",
       "[8 rows x 101 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at some statistics about our data set to decide if we need to normalize our features or not\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and labela\n",
    "x=dataset.copy()\n",
    "y = x[['Y']]\n",
    "del x['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 100) (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1508\n",
       " 1    1492\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if our problem is unbalanced problem or balanced\n",
    "dataset['Y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x=scaler.fit_transform(x)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size = 0.20, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try smple algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "svc=SVC(kernel=\"rbf\")#rbf\n",
    "gnb=GaussianNB()\n",
    "lg = LogisticRegression(random_state=0, solver='liblinear',multi_class='ovr')\n",
    "Qdanalysis = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "LD_analysis = QuadraticDiscriminantAnalysis()\n",
    "knn=neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "Dtree = DecisionTreeClassifier(random_state=0)\n",
    "Rf = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(12, 5), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#model fitting\n",
    "svc=svc.fit(x_train,y_train)\n",
    "gnb=gnb.fit(x_train,y_train)\n",
    "lg=lg.fit(x_train,y_train)\n",
    "Qdanalysis=Qdanalysis.fit(x_train,y_train)\n",
    "LD_analysis=LD_analysis.fit(x_train,y_train)\n",
    "knn=knn.fit(x_train,y_train)\n",
    "Dtree=Dtree.fit(x_train,y_train)\n",
    "Rf=Rf.fit(x_train,y_train)\n",
    "nn=nn.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy  0.5383333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.54      0.58      0.56       302\n",
      "     class 1       0.54      0.50      0.52       298\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.54      0.54      0.54       600\n",
      "weighted avg       0.54      0.54      0.54       600\n",
      "\n",
      "naive_bayes accuracy  0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.48      0.52      0.50       302\n",
      "     class 1       0.47      0.44      0.46       298\n",
      "\n",
      "    accuracy                           0.48       600\n",
      "   macro avg       0.48      0.48      0.48       600\n",
      "weighted avg       0.48      0.48      0.48       600\n",
      "\n",
      "Logistic regression accuracy  0.5283333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.53      0.50      0.51       302\n",
      "     class 1       0.52      0.56      0.54       298\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n",
      "quadratic disremenant accuracy  0.4866666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.49      0.47      0.48       302\n",
      "     class 1       0.48      0.50      0.49       298\n",
      "\n",
      "    accuracy                           0.49       600\n",
      "   macro avg       0.49      0.49      0.49       600\n",
      "weighted avg       0.49      0.49      0.49       600\n",
      "\n",
      "linear discremenant accuracy  0.5266666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.53      0.52      0.52       302\n",
      "     class 1       0.52      0.54      0.53       298\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n",
      "knn accuracy  0.4766666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.48      0.46      0.47       302\n",
      "     class 1       0.47      0.50      0.49       298\n",
      "\n",
      "    accuracy                           0.48       600\n",
      "   macro avg       0.48      0.48      0.48       600\n",
      "weighted avg       0.48      0.48      0.48       600\n",
      "\n",
      "D tree accuracy  0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.48      0.47      0.48       302\n",
      "     class 1       0.48      0.49      0.48       298\n",
      "\n",
      "    accuracy                           0.48       600\n",
      "   macro avg       0.48      0.48      0.48       600\n",
      "weighted avg       0.48      0.48      0.48       600\n",
      "\n",
      "R forest accuracy  0.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.49      0.45      0.47       302\n",
      "     class 1       0.49      0.53      0.51       298\n",
      "\n",
      "    accuracy                           0.49       600\n",
      "   macro avg       0.49      0.49      0.49       600\n",
      "weighted avg       0.49      0.49      0.49       600\n",
      "\n",
      "nural network  0.49833333333333335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.50      0.54      0.52       302\n",
      "     class 1       0.49      0.46      0.48       298\n",
      "\n",
      "    accuracy                           0.50       600\n",
      "   macro avg       0.50      0.50      0.50       600\n",
      "weighted avg       0.50      0.50      0.50       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing a classification report for each algorithm\n",
    "\n",
    "print(\"svm accuracy \",svc.score(x_test,y_test))\n",
    "y_score =  svc.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"naive_bayes accuracy \",gnb.score(x_test,y_test))\n",
    "y_score =  gnb.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"Logistic regression accuracy \",lg.score(x_test,y_test))\n",
    "y_score =  lg.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "print(\"quadratic disremenant accuracy \",Qdanalysis.score(x_test,y_test))\n",
    "y_score =  Qdanalysis.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "print(\"linear discremenant accuracy \",LD_analysis.score(x_test,y_test))\n",
    "y_score =  LD_analysis.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"knn accuracy \",knn.score(x_test,y_test))\n",
    "y_score =  knn.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"D tree accuracy \",Dtree.score(x_test,y_test))\n",
    "y_score =  Dtree.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"R forest accuracy \",Rf.score(x_test,y_test))\n",
    "y_score =  Rf.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"nural network \",nn.score(x_test,y_test))\n",
    "y_score =  nn.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression  and linear discremenant accuracy gives us the best accuracy here 53%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost 100 tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5233333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.53      0.50      0.52       302\n",
      "     class 1       0.52      0.55      0.54       298\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_trees = 100\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees)\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "model=model.fit(x_train,y_train)\n",
    "y_score =  model.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets try bagging algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-bagging ensample DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:645: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.49      0.45      0.47       302\n",
      "     class 1       0.48      0.52      0.50       298\n",
      "\n",
      "    accuracy                           0.48       600\n",
      "   macro avg       0.49      0.49      0.48       600\n",
      "weighted avg       0.49      0.48      0.48       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7)\n",
    "\n",
    "\n",
    "model=model.fit(x_train,y_train)\n",
    "y_score2 =  model.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.49      0.46      0.48       302\n",
      "     class 1       0.48      0.51      0.49       298\n",
      "\n",
      "    accuracy                           0.48       600\n",
      "   macro avg       0.49      0.49      0.48       600\n",
      "weighted avg       0.49      0.48      0.48       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model with over sampled data (teasted with over sampled data)\n",
    "#RandomForestClassifier\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "\n",
    "model=model.fit(x_train,y_train)\n",
    "y_score =  model.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doing pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=70)\n",
    "\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(principalDf,y, test_size = 0.3, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model fitting\n",
    "svc=SVC(kernel=\"rbf\")#rbf\n",
    "gnb=GaussianNB()\n",
    "lg = LogisticRegression(random_state=0, solver='liblinear',multi_class='ovr')\n",
    "Qdanalysis = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "LD_analysis = QuadraticDiscriminantAnalysis()\n",
    "knn=neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "Dtree = DecisionTreeClassifier(random_state=0)\n",
    "Rf = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(12, 5), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "svc=svc.fit(x_train,y_train)\n",
    "gnb=gnb.fit(x_train,y_train)\n",
    "lg=lg.fit(x_train,y_train)\n",
    "Qdanalysis=Qdanalysis.fit(x_train,y_train)\n",
    "LD_analysis=LD_analysis.fit(x_train,y_train)\n",
    "knn=knn.fit(x_train,y_train)\n",
    "Dtree=Dtree.fit(x_train,y_train)\n",
    "Rf=Rf.fit(x_train,y_train)\n",
    "nn=nn.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy  0.5311111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.53      0.68      0.59       452\n",
      "     class 1       0.54      0.38      0.44       448\n",
      "\n",
      "    accuracy                           0.53       900\n",
      "   macro avg       0.53      0.53      0.52       900\n",
      "weighted avg       0.53      0.53      0.52       900\n",
      "\n",
      "naive_bayes accuracy  0.5066666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.51      0.61      0.56       452\n",
      "     class 1       0.51      0.40      0.45       448\n",
      "\n",
      "    accuracy                           0.51       900\n",
      "   macro avg       0.51      0.51      0.50       900\n",
      "weighted avg       0.51      0.51      0.50       900\n",
      "\n",
      "Logistic regression accuracy  0.5255555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.53      0.57      0.55       452\n",
      "     class 1       0.53      0.48      0.50       448\n",
      "\n",
      "    accuracy                           0.53       900\n",
      "   macro avg       0.53      0.53      0.52       900\n",
      "weighted avg       0.53      0.53      0.52       900\n",
      "\n",
      "quadratic disremenant accuracy  0.4955555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.50      0.54      0.52       452\n",
      "     class 1       0.49      0.46      0.47       448\n",
      "\n",
      "    accuracy                           0.50       900\n",
      "   macro avg       0.50      0.50      0.49       900\n",
      "weighted avg       0.50      0.50      0.49       900\n",
      "\n",
      "linear discremenant accuracy  0.5044444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.51      0.60      0.55       452\n",
      "     class 1       0.50      0.41      0.45       448\n",
      "\n",
      "    accuracy                           0.50       900\n",
      "   macro avg       0.50      0.50      0.50       900\n",
      "weighted avg       0.50      0.50      0.50       900\n",
      "\n",
      "knn accuracy  0.4866666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.49      0.47      0.48       452\n",
      "     class 1       0.48      0.50      0.49       448\n",
      "\n",
      "    accuracy                           0.49       900\n",
      "   macro avg       0.49      0.49      0.49       900\n",
      "weighted avg       0.49      0.49      0.49       900\n",
      "\n",
      "D tree accuracy  0.4888888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.49      0.50      0.49       452\n",
      "     class 1       0.49      0.48      0.48       448\n",
      "\n",
      "    accuracy                           0.49       900\n",
      "   macro avg       0.49      0.49      0.49       900\n",
      "weighted avg       0.49      0.49      0.49       900\n",
      "\n",
      "R forest accuracy  0.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.49      0.49      0.49       452\n",
      "     class 1       0.49      0.49      0.49       448\n",
      "\n",
      "    accuracy                           0.49       900\n",
      "   macro avg       0.49      0.49      0.49       900\n",
      "weighted avg       0.49      0.49      0.49       900\n",
      "\n",
      "nural network  0.48333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.49      0.47      0.48       452\n",
      "     class 1       0.48      0.50      0.49       448\n",
      "\n",
      "    accuracy                           0.48       900\n",
      "   macro avg       0.48      0.48      0.48       900\n",
      "weighted avg       0.48      0.48      0.48       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"svm accuracy \",svc.score(x_test,y_test))\n",
    "y_score =  svc.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"naive_bayes accuracy \",gnb.score(x_test,y_test))\n",
    "y_score =  gnb.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"Logistic regression accuracy \",lg.score(x_test,y_test))\n",
    "y_score =  lg.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "print(\"quadratic disremenant accuracy \",Qdanalysis.score(x_test,y_test))\n",
    "y_score =  Qdanalysis.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "print(\"linear discremenant accuracy \",LD_analysis.score(x_test,y_test))\n",
    "y_score =  LD_analysis.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"knn accuracy \",knn.score(x_test,y_test))\n",
    "y_score =  knn.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"D tree accuracy \",Dtree.score(x_test,y_test))\n",
    "y_score =  Dtree.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"R forest accuracy \",Rf.score(x_test,y_test))\n",
    "y_score =  Rf.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n",
    "\n",
    "\n",
    "print(\"nural network \",nn.score(x_test,y_test))\n",
    "y_score =  nn.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression accuracy is the best 53%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doing feature selection to selct best k_features using Univariate feature selection with svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy  0.5466666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.54      0.65      0.59       302\n",
      "     class 1       0.55      0.45      0.49       298\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.55      0.55      0.54       600\n",
      "weighted avg       0.55      0.55      0.54       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=12).fit_transform(x, y)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_new,y, test_size = 0.20, stratify = y)\n",
    "\n",
    "svc=SVC(kernel=\"rbf\")#rbf\n",
    "\n",
    "svc=svc.fit(x_train,y_train)\n",
    "\n",
    "print(\"svm accuracy \",svc.score(x_test,y_test))\n",
    "y_score =  svc.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1-based feature selection with svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy  0.5683333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.56      0.66      0.61       302\n",
      "     class 1       0.58      0.47      0.52       298\n",
      "\n",
      "    accuracy                           0.57       600\n",
      "   macro avg       0.57      0.57      0.56       600\n",
      "weighted avg       0.57      0.57      0.56       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.04, penalty=\"l2\", dual=False).fit(x, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(x)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_new,y, test_size = 0.20, stratify = y)\n",
    "\n",
    "svc=SVC(kernel=\"rbf\")#rbf\n",
    "\n",
    "svc=svc.fit(x_train,y_train)\n",
    "\n",
    "print(\"svm accuracy \",svc.score(x_test,y_test))\n",
    "y_score =  svc.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based feature selection with svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy  0.565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.56      0.66      0.61       302\n",
      "     class 1       0.58      0.47      0.52       298\n",
      "\n",
      "    accuracy                           0.56       600\n",
      "   macro avg       0.57      0.56      0.56       600\n",
      "weighted avg       0.57      0.56      0.56       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=20)\n",
    "clf = clf.fit(x, y)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(x)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_new,y, test_size = 0.20, stratify = y)\n",
    "\n",
    "svc=SVC(kernel=\"rbf\")#rbf\n",
    "\n",
    "svc=svc.fit(x_train,y_train)\n",
    "\n",
    "print(\"svm accuracy \",svc.score(x_test,y_test))\n",
    "y_score =  svc.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doing feature selection to selct best k_features using Univariate feature selection  with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy  0.5466666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.55      0.58      0.56       302\n",
      "     class 1       0.55      0.52      0.53       298\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.55      0.55      0.55       600\n",
      "weighted avg       0.55      0.55      0.55       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=8).fit_transform(x, y)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_new,y, test_size = 0.20, stratify = y)\n",
    "\n",
    "lg = LogisticRegression(random_state=0, solver='liblinear',multi_class='ovr')\n",
    "\n",
    "lg=lg.fit(x_train,y_train)\n",
    "\n",
    "print(\"Logistic regression accuracy \",lg.score(x_test,y_test))\n",
    "y_score =  lg.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1-based feature selection with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy  0.555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.56      0.56      0.56       302\n",
      "     class 1       0.55      0.55      0.55       298\n",
      "\n",
      "    accuracy                           0.56       600\n",
      "   macro avg       0.55      0.55      0.55       600\n",
      "weighted avg       0.55      0.56      0.55       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.04, penalty=\"l2\", dual=False).fit(x, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(x)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_new,y, test_size = 0.20, stratify = y)\n",
    "\n",
    "lg = LogisticRegression(random_state=0, solver='liblinear',multi_class='ovr')\n",
    "\n",
    "lg=lg.fit(x_train,y_train)\n",
    "\n",
    "print(\"Logistic regression accuracy \",lg.score(x_test,y_test))\n",
    "y_score =  lg.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based feature selection  with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy  0.5433333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.55      0.56      0.55       302\n",
      "     class 1       0.54      0.53      0.53       298\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.54      0.54      0.54       600\n",
      "weighted avg       0.54      0.54      0.54       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bassam.abdelmohsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=20)\n",
    "clf = clf.fit(x, y)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(x)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_new,y, test_size = 0.20, stratify = y)\n",
    "\n",
    "lg = LogisticRegression(random_state=0, solver='liblinear',multi_class='ovr')\n",
    "\n",
    "lg=lg.fit(x_train,y_train)\n",
    "\n",
    "print(\"Logistic regression accuracy \",lg.score(x_test,y_test))\n",
    "y_score =  lg.predict(x_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and labela\n",
    "sel = VarianceThreshold()\n",
    "sel.fit(x)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x[:, sel.variances_ > .09 ],y, test_size = 0.20, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07172049, 0.01443846, 0.07504806, 0.04267225, 0.0486472 ,\n",
       "       0.03263537, 0.04270665, 0.04213533, 0.02342241, 0.02309702,\n",
       "       0.02737271, 0.03831155, 0.0547839 , 0.0586322 , 0.05003538,\n",
       "       0.06216854, 0.03207373, 0.03173641, 0.0303415 , 0.04174804,\n",
       "       0.04893645, 0.04173053, 0.03375502, 0.02962171, 0.06560349,\n",
       "       0.0629992 , 0.05548406, 0.10640793, 0.05352567, 0.02515265,\n",
       "       0.03347835, 0.08706565, 0.06408968, 0.05789462, 0.05575573,\n",
       "       0.06449461, 0.04674999, 0.03193307, 0.05676907, 0.03855196,\n",
       "       0.02295909, 0.05448986, 0.05760368, 0.05352183, 0.07219228,\n",
       "       0.09500219, 0.04997711, 0.05529174, 0.05924098, 0.04766259,\n",
       "       0.03099719, 0.05500566, 0.08149357, 0.05111941, 0.05356501,\n",
       "       0.05114671, 0.03969739, 0.02012478, 0.07166471, 0.03158695,\n",
       "       0.08405478, 0.035681  , 0.08467906, 0.01623197, 0.05748761,\n",
       "       0.02901769, 0.03419951, 0.04317636, 0.06891731, 0.03259284,\n",
       "       0.05459185, 0.0360182 , 0.0327951 , 0.0443258 , 0.05035081,\n",
       "       0.06563894, 0.07155637, 0.07388404, 0.05294447, 0.04520166,\n",
       "       0.04473667, 0.05422257, 0.04571354, 0.04749495, 0.07296563,\n",
       "       0.06216324, 0.05452298, 0.05110533, 0.04809781, 0.07070487,\n",
       "       0.03730362, 0.02821208, 0.05981433, 0.0213472 , 0.05379203,\n",
       "       0.04104051, 0.02683649, 0.05295955, 0.04931838, 0.0193969 ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, sel.variances_ > .09 ].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
